{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7fb0197-ada0-4de8-ad2b-c05eec940168",
   "metadata": {},
   "source": [
    "<h1> Pandas </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b19da1e-a7ab-4a61-922f-80703bf71027",
   "metadata": {},
   "source": [
    "One Notebook for handling all important functions for using pandas library along with example use-cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5315c3d-a9e8-4870-b70a-9c87d25280d6",
   "metadata": {},
   "source": [
    "<h3> Handling Dataframes </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7064ec6-1434-4923-88b5-d91902cad50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96b1262d-dc65-4c52-a947-6d06f85459ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = {'animal': ['cat', 'cat', 'snake', 'dog', 'dog', 'cat', 'snake', 'cat', 'dog', 'dog'],\n",
    "        'age': [2.5, 3, 0.5, np.nan, 5, 2, 4.5, np.nan, 7, 3],\n",
    "        'visits': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "        'priority': ['yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no']}\n",
    "\n",
    "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "\n",
    "df = pd.DataFrame(data,index=labels)\n",
    "\n",
    "\n",
    "# df = pd.DataFrame(Dictionary, index = labels)\n",
    "\"\"\"\n",
    "Index will contain new row naming values; Default row indices will be numerical starting from 1\n",
    "\n",
    "Keys -> Column Names\n",
    "Values -> Row Values in that column(Key)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e76866f9-cdb2-4e51-bef4-b48d286bb27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INSTALLED VERSIONS\n",
      "------------------\n",
      "commit                : 0691c5cf90477d3503834d983f69350f250a6ff7\n",
      "python                : 3.10.0\n",
      "python-bits           : 64\n",
      "OS                    : Windows\n",
      "OS-release            : 10\n",
      "Version               : 10.0.22631\n",
      "machine               : AMD64\n",
      "processor             : Intel64 Family 6 Model 165 Stepping 2, GenuineIntel\n",
      "byteorder             : little\n",
      "LC_ALL                : None\n",
      "LANG                  : None\n",
      "LOCALE                : English_India.1252\n",
      "\n",
      "pandas                : 2.2.3\n",
      "numpy                 : 2.2.6\n",
      "pytz                  : 2025.2\n",
      "dateutil              : 2.9.0.post0\n",
      "pip                   : 25.1.1\n",
      "Cython                : None\n",
      "sphinx                : None\n",
      "IPython               : 8.36.0\n",
      "adbc-driver-postgresql: None\n",
      "adbc-driver-sqlite    : None\n",
      "bs4                   : 4.13.4\n",
      "blosc                 : None\n",
      "bottleneck            : None\n",
      "dataframe-api-compat  : None\n",
      "fastparquet           : None\n",
      "fsspec                : None\n",
      "html5lib              : None\n",
      "hypothesis            : None\n",
      "gcsfs                 : None\n",
      "jinja2                : 3.1.6\n",
      "lxml.etree            : None\n",
      "matplotlib            : 3.10.3\n",
      "numba                 : None\n",
      "numexpr               : None\n",
      "odfpy                 : None\n",
      "openpyxl              : 3.1.5\n",
      "pandas_gbq            : None\n",
      "psycopg2              : None\n",
      "pymysql               : 1.4.6\n",
      "pyarrow               : None\n",
      "pyreadstat            : None\n",
      "pytest                : None\n",
      "python-calamine       : None\n",
      "pyxlsb                : None\n",
      "s3fs                  : None\n",
      "scipy                 : 1.15.3\n",
      "sqlalchemy            : None\n",
      "tables                : None\n",
      "tabulate              : None\n",
      "xarray                : None\n",
      "xlrd                  : None\n",
      "xlsxwriter            : None\n",
      "zstandard             : None\n",
      "tzdata                : 2024.1\n",
      "qtpy                  : None\n",
      "pyqt5                 : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10 entries, a to j\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   animal    10 non-null     object \n",
      " 1   age       8 non-null      float64\n",
      " 2   visits    10 non-null     int64  \n",
      " 3   priority  10 non-null     object \n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 700.0+ bytes\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot set a row with mismatched columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# ADDING NEW ROWS\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWinsimxr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYellow\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Adding rows using dictionary\u001b[39;00m\n\u001b[0;32m     16\u001b[0m new_row \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m10\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m11\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m12\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m21\u001b[39m]})\n",
      "File \u001b[1;32mC:\\PythonCode\\ramis\\lib\\site-packages\\pandas\\core\\indexing.py:911\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    910\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[1;32m--> 911\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\PythonCode\\ramis\\lib\\site-packages\\pandas\\core\\indexing.py:1932\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1929\u001b[0m     indexer, missing \u001b[38;5;241m=\u001b[39m convert_missing_indexer(indexer)\n\u001b[0;32m   1931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[1;32m-> 1932\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1936\u001b[0m     \u001b[38;5;66;03m# must come after setting of missing\u001b[39;00m\n",
      "File \u001b[1;32mC:\\PythonCode\\ramis\\lib\\site-packages\\pandas\\core\\indexing.py:2306\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_missing\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m   2303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_list_like_indexer(value):\n\u001b[0;32m   2304\u001b[0m         \u001b[38;5;66;03m# must have conforming columns\u001b[39;00m\n\u001b[0;32m   2305\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[1;32m-> 2306\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot set a row with mismatched columns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2308\u001b[0m     value \u001b[38;5;241m=\u001b[39m Series(value, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolumns, name\u001b[38;5;241m=\u001b[39mindexer)\n\u001b[0;32m   2310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj):\n\u001b[0;32m   2311\u001b[0m     \u001b[38;5;66;03m# We will ignore the existing dtypes instead of using\u001b[39;00m\n\u001b[0;32m   2312\u001b[0m     \u001b[38;5;66;03m#  internals.concat logic\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot set a row with mismatched columns"
     ]
    }
   ],
   "source": [
    "# Checking pandas info\n",
    "pd.__version__\n",
    "pd.show_versions()\n",
    "\n",
    "\n",
    "# Dataframe Details\n",
    "df.info()\n",
    "df.describe()\n",
    "df.columns\n",
    "\n",
    "\n",
    "# ADDING NEW ROWS\n",
    "df.loc[3] = [\"Winsimxr\", \"Yellow\"]\n",
    "\n",
    "# Adding rows using dictionary\n",
    "new_row = pd.DataFrame({'A': [10], 'B': [11], 'C': [12], 'D': [21]})\n",
    "df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "# Here ignore_index = True, will make it add as new row to our existing table\n",
    "# If ignore_index is ommited, this new row will still be added but its index will be 0\n",
    "\"\"\"\n",
    "A table have indices of rows as 0,1,2\n",
    "B is a new row\n",
    "If we used concat on both without using ignore_index=True\n",
    "\n",
    "New table A will have indices of rows as follows:\n",
    "0,1,2,0\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ADDING NEW COLUMNS\n",
    "df[\"New_Column_Name\"] = [\"val1\", \"val2\"]\n",
    "\n",
    "# Combining two dataframes\n",
    "# Both DFs should have same number of rows and aligned indexes\n",
    "# If there is any mismatch values will be filled with NaN\n",
    "result = pd.concat([df1,df2],axis=1)\n",
    "\n",
    "# To get rid of index error use\n",
    "df1 = df1.reset_index(drop=True)\n",
    "df2 = df2.reset_index(drop=True)\n",
    "result = pd.concat([df1, df2], axis=1)\n",
    "# If drop=True is not used - It will add new column of indices at the starting new column\n",
    "\n",
    "\n",
    "\"\"\"-----------------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "\n",
    "# Dropping rows\n",
    "df = df.drop(1)\n",
    "df = df.drop(\"b\")\n",
    "df.drop(\"b\", inplace=True) # For making changes in place\n",
    "df = df.drop([\"a\",\"c\"])\n",
    "df = df.drop(df.loc[\"a\":\"c\"].index)\n",
    "\n",
    "# Dropping columns\n",
    "df = df.drop(\"Name\", axis=1)\n",
    "df = df.drop([\"Name\",\"Age\"], axis=1)\n",
    "df = df.drop(columns = [\"Name\",\"age\"])\n",
    "df = df.drop(df.columns[2:5], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1c1f8a7d-5e2e-49e1-9baa-8c5dd38a2c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>snake</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>dog</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>cat</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  animal  age\n",
       "c  snake  0.5\n",
       "d    dog  NaN\n",
       "f    cat  2.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loc - label-based indexing\n",
    "df.loc[\"a\"]\n",
    "df.loc[\"a\",\"animal\"]\n",
    "\n",
    "df.loc[\"a\":\"c\",]\n",
    "df.loc[\"a\":\"c\",\"animal\"]\n",
    "df.loc[\"a\":\"c\",\"animal\":\"priority\"]\n",
    "\n",
    "df.loc[\"a\":\"c\",[\"animal\",\"priority\"]]\n",
    "df.loc[[\"a\",\"c\"],\"animal\":\"priority\"]\n",
    "df.loc[[\"a\",\"c\"],[\"animal\",\"priority\"]]\n",
    "\n",
    "\n",
    "# iloc - Integer(position) based indexing\n",
    "df.iloc[1,]\n",
    "df.iloc[[1,2,4],]\n",
    "df.iloc[1:4,]\n",
    "df.iloc[1:3,1:4]\n",
    "\n",
    "df.loc[df.index[6],[\"animal\",\"age\"]]\n",
    "df.loc[df.index[3:8],[\"animal\",\"age\"]]\n",
    "df.loc[df.index[[2,3,5]],[\"animal\",\"age\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2b7eb1b6-9ce8-44f1-8c79-fea7acb4bec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# READING FILES\n",
    "\n",
    "df = pd.read_csv(\"filename.csv\", low_memory=False)\n",
    "df = pd.read_excel(\"filename.xlsx\")\n",
    "df = pd.read_pickle(\"filename.pkl\")\n",
    "df = pd.read_json(\"filename.json\")\n",
    "df = pd.read_html(\"https://ramis.com/tablepage\")\n",
    "df = pd.read_parquet(\"filename.parquet\")\n",
    "df = pd.read_sql(\"SELECT * FROM TABLE\", connection)\n",
    "\n",
    "# Reading CSVs in chunks - It uses mechanism similar to generator\n",
    "\n",
    "chunk_iter = pd.read_csv(\"filename.csv\", chunksize=10000) # Here chunk_iter is a generator like object called TextFileReader object\n",
    "\n",
    "# Using list comprehension\n",
    "result = pd.concat([chunk for chunk in pd.read_csv(\"filename.csv\",chunksize=5000)])\n",
    "\n",
    "# Using generator - more memory efficient\n",
    "result = pd.concat((chunk for chunk in pd.read_csv(\"filename.csv\",chunksize=5000)))\n",
    "\n",
    "# Reading specific columns from a csv file\n",
    "cols = [\"Name\", \"Age\", \"Color\"]\n",
    "df = pd.read_csv(\"filename.csv\", usecols=cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff3c7f68-9b14-4e14-907f-99189c3223d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITING FILES\n",
    "\n",
    "df.to_csv(\"output.csv\", index=False)\n",
    "df.to_excel(\"output.csv\", index=False)\n",
    "df.to_json(\"output.json\", orient='records') # orient=\"columns\" for column centric view\n",
    "df.to_html(\"output.html\")\n",
    "df.to_sql(\"table\", con=engine, if_exists=\"replace\")\n",
    "df.to_parquet(\"output.parquet\", index=False)\n",
    "df.to_pickle(\"output.pkl\")\n",
    "\n",
    "\n",
    "import json\n",
    "with open(\"file.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# json.loads(data) Loading JSON Dict objects\n",
    "# json.dumps(data) -> dictionary to JSON\n",
    "\n",
    "# If using JSON with files - function names will become\n",
    "# json.load() and json.dump()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1819b825-efbe-4d20-85c1-6b401b4b31c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL JOINS\n",
    "\n",
    "# Outer Join\n",
    "result = pd.merge(df1, df2, on='id', how='outer')\n",
    "\n",
    "\"\"\"\n",
    "Select * from table T1\n",
    "FULL OUTER JOIN table T2\n",
    "ON\n",
    "T1.id = T2.id\n",
    "\"\"\"\n",
    "\n",
    "# Inner Join\n",
    "result = pd.merge(df1, df2, on='id', how='inner')\n",
    "\n",
    "\"\"\"\n",
    "Select * from table T1\n",
    "INNER JOIN table T2\n",
    "ON\n",
    "T1.id = T2.id\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Left Join\n",
    "result = pd.merge(df1, df2, on='id', how='left')\n",
    "\n",
    "\"\"\"\n",
    "Select * from table T1\n",
    "LEFT JOIN table T2\n",
    "ON\n",
    "T1.id = T2.id\n",
    "\"\"\"\n",
    "\n",
    "# Right Join\n",
    "result = pd.merge(df1, df2, on='id', how='right')\n",
    "\n",
    "\"\"\"\n",
    "Select * from table T1\n",
    "RIGHT JOIN table T2\n",
    "ON\n",
    "T1.id = T2.id\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d86902-f651-4371-8cb7-2d3c965e3936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling NA\n",
    "\n",
    "df.isnull()\n",
    "df.dropna()\n",
    "df.fillna()\n",
    "df.rename(columns{'old':'new'})\n",
    "df.columns = [\"A\",\"B\"]\n",
    "df.replace(old,new)\n",
    "df.apply(func)\n",
    "\n",
    "df.pivot(index, columns, values)\n",
    "\"\"\"\n",
    "pivoted = df.pivot(index=\"Color\", columns=\"Names\", values=\"Alias\")\n",
    "\"\"\"\n",
    "# If index+columns are not unique then go for pivot_table\n",
    "\n",
    "df.pivot_table()\n",
    "\"\"\"\n",
    "pivoted = df.pivot_table(index=\"Color\", columns=\"Names\", values=\"Alias\", aggfunc=\"count\")\n",
    "\"\"\"\n",
    "\n",
    "df.melt(df) # unpivot\n",
    "\"\"\"\n",
    "melted = pd.melt(df, id_vars='Color', var_name='Names', value_name='Alias')\n",
    "\"\"\"\n",
    "\n",
    "transposed = df.T\n",
    "\n",
    "df.reset_index() # Defaults indices to 0,1,2 etc\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
